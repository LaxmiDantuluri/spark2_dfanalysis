{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Builder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# The autoreload extension is already loaded. To reload it, use:\n",
    "#  %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\n"
     ]
    }
   ],
   "source": [
    "print(os.path.dirname(sys.executable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mylib:\n",
    "my_library = os.path.expanduser('~/.myconfigs')\n",
    "my_spark = os.path.expanduser('~/spark2_dfanalysis')\n",
    "sys.path.append(my_library)\n",
    "sys.path.append(my_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d810216/.myconfigs\n",
      "C:\\Users\\d810216/spark2_dfanalysis\n",
      "['.git', '.gitignore', 'builder', 'example_notebooks', 'LICENSE', 'README.md', 'shared', '__init__.py']\n"
     ]
    }
   ],
   "source": [
    "# print(sys.path)\n",
    "print(my_library)\n",
    "print(my_spark)\n",
    "print(os.listdir(my_spark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# spark = SparkSession.builder.appName('myappname').getOrCreate()\n",
    "# print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(dir(pyspark))\n",
    "# print(dir(pyspark.sql))\n",
    "# print(dir(pyspark.rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002C5E66E0B00>\n"
     ]
    }
   ],
   "source": [
    "from shared.app_context import *\n",
    "\n",
    "ctx = ApplicationContext(\"Dev-Job\")\n",
    "print(ctx.spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(sys.path)\n",
    "from builder.DataFrameBuild import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameBuild\n",
    "### x = DataFrameBuild(ctx.spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'builder.DataFrameBuild.DataFrameBuild'>\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'arrays_to_dataframe', 'build_array', 'get_StructField', 'print_size', 'spark']\n",
      "<pyspark.sql.session.SparkSession object at 0x000002C5E66E0B00>\n"
     ]
    }
   ],
   "source": [
    "x = DataFrameBuild(ctx.spark)\n",
    "print(type(x))\n",
    "print(dir(x))\n",
    "print(x.spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']\n",
      "12 [3 1 3 1 0 3 4 1 2 1 0 3]\n",
      "12 [10.03311284 10.03815753 10.04005895 10.09301454 10.0645929  10.04592987\n",
      " 10.02605554 10.0741538  10.00008683 10.04075202 10.03649303 10.06943678]\n"
     ]
    }
   ],
   "source": [
    "mystr = x.build_array(\"string\",num=12,width=8) \n",
    "myint = x.build_array(\"integer\",num=12,nrange=(0,4))    # inclusive on range\n",
    "mydoub = x.build_array(\"double\",num=12,nrange=(10,10.1))\n",
    "\n",
    "print(len(mystr),mystr)\n",
    "print(len(myint),myint)\n",
    "print(len(mydoub),mydoub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with a list of list of strings, and list of string of length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check:\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']] 1\n",
      "['random_letters']\n",
      "12\n",
      "+--------------+\n",
      "|random_letters|\n",
      "+--------------+\n",
      "|      qvfdlpks|\n",
      "|      vpyviyux|\n",
      "|      ypqyinsl|\n",
      "|      rigvlcog|\n",
      "|      qngoiobg|\n",
      "|      zurnglnj|\n",
      "|      hsuemdkh|\n",
      "|      vlfalaxs|\n",
      "|      hsmjolqj|\n",
      "|      uhvkberg|\n",
      "|      ladwcapa|\n",
      "|      qrbkjsql|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx = x.arrays_to_dataframe([mystr],['random_letters'])\n",
    "print(dfx.count())\n",
    "dfx.show()\n",
    "\n",
    "# [StructField(str,StringType,true)]\n",
    "# ['str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with a list of list of strings, and a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levels:\n",
      "list list\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']]\n",
      "check:\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']] 1\n",
      "['random_letters']\n",
      "12\n",
      "+--------------+\n",
      "|random_letters|\n",
      "+--------------+\n",
      "|      qvfdlpks|\n",
      "|      vpyviyux|\n",
      "|      ypqyinsl|\n",
      "|      rigvlcog|\n",
      "|      qngoiobg|\n",
      "|      zurnglnj|\n",
      "|      hsuemdkh|\n",
      "|      vlfalaxs|\n",
      "|      hsmjolqj|\n",
      "|      uhvkberg|\n",
      "|      ladwcapa|\n",
      "|      qrbkjsql|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx = x.arrays_to_dataframe([mystr],'random_letters')\n",
    "print(dfx.count())\n",
    "dfx.show()\n",
    "\n",
    "# [StructField(str,StringType,true)]\n",
    "# ['str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with lists of length 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 3 1 0 3 4 1 2 1 0 3]\n",
      "['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']\n",
      "Levels:\n",
      "list ndarray\n",
      "[array([3, 1, 3, 1, 0, 3, 4, 1, 2, 1, 0, 3]), ['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']]\n",
      "check:\n",
      "[array([3, 1, 3, 1, 0, 3, 4, 1, 2, 1, 0, 3]), ['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']] 2\n",
      "['random_ints', 'random_letters']\n",
      "12\n",
      "+-----------+--------------+\n",
      "|random_ints|random_letters|\n",
      "+-----------+--------------+\n",
      "|          3|      qvfdlpks|\n",
      "|          1|      vpyviyux|\n",
      "|          3|      ypqyinsl|\n",
      "|          1|      rigvlcog|\n",
      "|          0|      qngoiobg|\n",
      "|          3|      zurnglnj|\n",
      "|          4|      hsuemdkh|\n",
      "|          1|      vlfalaxs|\n",
      "|          2|      hsmjolqj|\n",
      "|          1|      uhvkberg|\n",
      "|          0|      ladwcapa|\n",
      "|          3|      qrbkjsql|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(myint)\n",
    "print(mystr)\n",
    "dfx = x.arrays_to_dataframe([myint,mystr],['random_ints','random_letters'])\n",
    "print(dfx.count())\n",
    "dfx.show()\n",
    "\n",
    "# [StructField(str,StringType,true)]\n",
    "# ['str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with a list and a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levels:\n",
      "list str\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']]\n",
      "check:\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']] 1\n",
      "['crazy_strings']\n",
      "12\n",
      "+-------------+\n",
      "|crazy_strings|\n",
      "+-------------+\n",
      "|     qvfdlpks|\n",
      "|     vpyviyux|\n",
      "|     ypqyinsl|\n",
      "|     rigvlcog|\n",
      "|     qngoiobg|\n",
      "|     zurnglnj|\n",
      "|     hsuemdkh|\n",
      "|     vlfalaxs|\n",
      "|     hsmjolqj|\n",
      "|     uhvkberg|\n",
      "|     ladwcapa|\n",
      "|     qrbkjsql|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx = x.arrays_to_dataframe(mystr,'crazy_strings')\n",
    "print(dfx.count())\n",
    "dfx.show()\n",
    "\n",
    "# [StructField(str,StringType,true)]\n",
    "# ['str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with an array and a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levels:\n",
      "ndarray None\n",
      "[array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
      "       26., 27., 28., 29., 30.])]\n",
      "check:\n",
      "[array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
      "       26., 27., 28., 29., 30.])] 1\n",
      "['integers']\n",
      "31\n",
      "+--------+\n",
      "|integers|\n",
      "+--------+\n",
      "|     0.0|\n",
      "|     1.0|\n",
      "|     2.0|\n",
      "|     3.0|\n",
      "|     4.0|\n",
      "|     5.0|\n",
      "|     6.0|\n",
      "|     7.0|\n",
      "|     8.0|\n",
      "|     9.0|\n",
      "|    10.0|\n",
      "|    11.0|\n",
      "|    12.0|\n",
      "|    13.0|\n",
      "|    14.0|\n",
      "|    15.0|\n",
      "|    16.0|\n",
      "|    17.0|\n",
      "|    18.0|\n",
      "|    19.0|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx = x.arrays_to_dataframe(np.linspace(0,30,31),'integers')\n",
    "print(dfx.count())\n",
    "dfx.show()\n",
    "\n",
    "# [StructField(str,StringType,true)]\n",
    "# ['str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with 1 array, no names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levels:\n",
      "list str\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']]\n",
      "check:\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql']] 1\n",
      "['str']\n",
      "12\n",
      "+--------+\n",
      "|     str|\n",
      "+--------+\n",
      "|qvfdlpks|\n",
      "|vpyviyux|\n",
      "|ypqyinsl|\n",
      "|rigvlcog|\n",
      "|qngoiobg|\n",
      "|zurnglnj|\n",
      "|hsuemdkh|\n",
      "|vlfalaxs|\n",
      "|hsmjolqj|\n",
      "|uhvkberg|\n",
      "|ladwcapa|\n",
      "|qrbkjsql|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx = x.arrays_to_dataframe(mystr)\n",
    "print(dfx.count())\n",
    "dfx.show()\n",
    "\n",
    "# [StructField(str,StringType,true)]\n",
    "# ['str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with 3 arrays, no names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levels:\n",
      "list list\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql'], array([3, 1, 3, 1, 0, 3, 4, 1, 2, 1, 0, 3]), array([10.03311284, 10.03815753, 10.04005895, 10.09301454, 10.0645929 ,\n",
      "       10.04592987, 10.02605554, 10.0741538 , 10.00008683, 10.04075202,\n",
      "       10.03649303, 10.06943678])]\n",
      "check:\n",
      "[['qvfdlpks', 'vpyviyux', 'ypqyinsl', 'rigvlcog', 'qngoiobg', 'zurnglnj', 'hsuemdkh', 'vlfalaxs', 'hsmjolqj', 'uhvkberg', 'ladwcapa', 'qrbkjsql'], array([3, 1, 3, 1, 0, 3, 4, 1, 2, 1, 0, 3]), array([10.03311284, 10.03815753, 10.04005895, 10.09301454, 10.0645929 ,\n",
      "       10.04592987, 10.02605554, 10.0741538 , 10.00008683, 10.04075202,\n",
      "       10.03649303, 10.06943678])] 3\n",
      "['str', 'int32', 'float64']\n",
      "<bound method DataFrame.count of DataFrame[str: string, int32: bigint, float64: double]>\n",
      "+--------+-----+------------------+\n",
      "|     str|int32|           float64|\n",
      "+--------+-----+------------------+\n",
      "|qvfdlpks|    3|10.033112836163543|\n",
      "|vpyviyux|    1|10.038157530035122|\n",
      "|ypqyinsl|    3|10.040058954249197|\n",
      "|rigvlcog|    1|10.093014535823126|\n",
      "|qngoiobg|    0|10.064592903919403|\n",
      "|zurnglnj|    3|10.045929866844363|\n",
      "|hsuemdkh|    4|10.026055540306302|\n",
      "|vlfalaxs|    1| 10.07415380380531|\n",
      "|hsmjolqj|    2| 10.00008683187471|\n",
      "|uhvkberg|    1| 10.04075202015893|\n",
      "|ladwcapa|    0|10.036493033207824|\n",
      "|qrbkjsql|    3|10.069436779293813|\n",
      "+--------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx = x.arrays_to_dataframe([mystr,myint,mydoub])\n",
    "print(dfx.count)\n",
    "dfx.show()\n",
    "\n",
    "# [StructField(str,StringType,true)]\n",
    "# ['str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1000 = DataFrameBuild(ctx.spark).arrays_to_dataframe([np.linspace(0,1000,1001)],[\"millenium\"])\n",
    "df1000.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fruit = [\"apple\",\"orange\",\"banana\",\"grape\",\"melon\",\"pineapple\",\"kiwi\",\"lemon\",\"lime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fruit = x.spark.createDataFrame(fruit,StringType()).toDF(\"fruit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fruit.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_fields(lst):\n",
    "    n = len(lst)\n",
    "    fields = [StructField(x,StringType(),True) for x in lst]\n",
    "    return fields\n",
    "\n",
    "fields_fruit = get_string_fields(fruit)\n",
    "# df = x.spark.createDataFrame(fruit,fields_fruit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fruit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b748d01e5350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrameBuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfruit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfruit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfruit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_fruit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays_to_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfruit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfruit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fruit1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"fruit2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fruit' is not defined"
     ]
    }
   ],
   "source": [
    "X = DataFrameBuild(ctx.spark)\n",
    "print(fruit,type(fruit))\n",
    "print(len(fruit))\n",
    "\n",
    "df_fruit = X.arrays_to_dataframe([fruit,fruit],[\"fruit1\",\"fruit2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_num_fruit.columns)\n",
    "print(df_fruit.columns)\n",
    "print(df_random_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_num_fruit.count())\n",
    "print(df_fruit.count())\n",
    "print(df_random_num.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_f2 = df_num_fruit.unionAll(df_fruit)\n",
    "# unionAll appends 2nd dataframe to the end of the 1st\n",
    "# Vertical Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_f2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_com = df_num_fruit.join(df_fruit,df_num_fruit['Index'] != df_fruit[\"fruit\"],\"outer\")\n",
    "\n",
    "# horizontal join, but non inner.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_com.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = DataFrameBuild(ctx.spark)\n",
    "df_multi = x.df_multidimensional(4,3,[('name','string',6),\n",
    "                                      ('address','integer',(1000,9999)),\n",
    "                                      ('portion','double',(0.0,1.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example 2. Another random, multidimensional dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = DataFrameBuild(ctx.spark)\n",
    "df_multi6 = x.df_multidimensional(500,6,[('user','string',6),\n",
    "                                         ('id','integer',(1,10000)),\n",
    "                                         ('password','string2',13),\n",
    "                                         ('address','integer',(1000,9999)),\n",
    "                                         ('decimal','double',(0.0,1.0)),\n",
    "                                         ('worth','double',(0.0,10000000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_multi6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3. build_array --> to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = DataFrameBuild(ctx.spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.build_array.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = x.build_array(\"string\",num=12,width=8) \n",
    "myint = x.build_array(\"integer\",num=12,nrange=(0,4))    # inclusive on range\n",
    "mydoub = x.build_array(\"double\",num=12,nrange=(10,10.1))\n",
    "\n",
    "print(len(mystr),mystr)\n",
    "print(len(myint),myint)\n",
    "print(len(mydoub),mydoub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of arrays .. pass into function, tell function to get type, zip.\n",
    "x = DataFrameBuild(ctx.spark)\n",
    "\n",
    "lst_names = [\"passwords\",\"quarter\",\"tens\"]\n",
    "lst = [mystr,myint,mydoub]\n",
    "\n",
    "df = x.df_from_arrays(lst,lst_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4. Choose array type, get DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = DataFrameBuild(ctx.spark)\n",
    "num = 500\n",
    "df4 = x.arrays_to_dataframe([x.build_array(\"string\",num=num,width=8),\n",
    "                        x.build_array(\"integer\",num=num,nrange=(1,4)),\n",
    "                        x.build_array(\"integer\",num=num,nrange=(1,12)),\n",
    "                        x.build_array(\"double\",num=num,nrange=(0.0,10000))],\n",
    "                      ['passwords','quarter','month','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build some arrays, put them into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = DataFrameBuild(ctx.spark)\n",
    "num = 500\n",
    "df4 = x.arrays_to_dataframe([[int(x) for x in np.linspace(1,num,num)],\n",
    "                             x.build_array(\"string\",num=num,width=8),\n",
    "                             x.build_array(\"integer\",num=num,nrange=(1,4)),\n",
    "                             x.build_array(\"integer\",num=num,nrange=(1,12)),\n",
    "                             x.build_array(\"double\",num=num,nrange=(0.0,10000))],\n",
    "                             ['index','passwords','quarter','month','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.orderBy(\"index\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.select(\"index\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

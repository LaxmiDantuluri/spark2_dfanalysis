# Let's explore Spark DataFrames
Dataframe analysis in PySpark!

<!-- [(home)](https://dmerz75.github.io/spark2_dfanalysis)
[(git-home)](https://github.com/dmerz75/spark2_dfanalysis) -->
<!-- [Iridium](https://dmerz75.github.io/iridium_catalyst/) for details. -->

## Start Spark | Construct Dataframes | Read/Write
Let's build some dataframes so that we have something with which to work.
We'll do some basic reading, writing, partitioning and maybe discuss certain
parameter advantages and disadvantages.

### The Basics:
  - [Initial Configuration](pages/build/Initial_Configuration.md)
    Initial Spark settings.
  - [Build/Construct](pages/build/Building_DataFrames.md)
  - [Read/Write/Partition](pages/build/Read_Write_Partition.md)
### The Basics & more. (coming soon!)
  - Read in dataframe, do a basic comparison.
  - Read/write for loop with some count/logical comparisons.


## Common Transformations and Analysis
Let's do some common dataframe manipulations. I'll show what I expect are some
common column formatting issues, occurrences, and operations you're likely to see.
We'll cover aggregations, grouping, and ordering.
  - [Transformations](pages/common/Transformations.md)
  - [Analysis](pages/common/Analysis.md)
  - Joins (coming soon!)
